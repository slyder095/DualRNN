{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has been implemented using Tensorflow 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import code.rnn_tf as rnn_tf\n",
    "import code.rnn_elman as rnn_elman # Con ruido\n",
    "import code.rnn_xhcy as rnn_xhcy # Dual CPU + Mem (conectada a CPU)\n",
    "\n",
    "import matplotlib.patches as mpatch\n",
    "\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posible values: BxA, paridad, tomita1, tomita2, tomita3, tomita4, tomita5, tomita6, tomita7\n",
    "\n",
    "problema = \"paridad\"\n",
    "\n",
    "\n",
    "input_file = \"files/train/\" + problema + \"_train_x.txt\"\n",
    "output_file = \"files/train/\" + problema + \"_train_y.txt\"\n",
    "test_largas_input = \"files/test/\" + problema + \"_cadenasLargas_x.txt\"\n",
    "test_largas_output = \"files/test/\" + problema + \"_cadenasLargas_y.txt\"\n",
    "test_extremo_muchasA_input = \"files/test/\" + problema + \"_extremo_muchasA_x.txt\"\n",
    "test_extremo_muchasA_output = \"files/test/\" + problema + \"_extremo_muchasA_y.txt\"\n",
    "test_extremo_muchasB_input = \"files/test/\" + problema + \"_extremo_muchasB_x.txt\"\n",
    "test_extremo_muchasB_output = \"files/test/\" + problema + \"_extremo_muchasB_y.txt\"\n",
    "test_grande_input = \"files/test/\" + problema + \"_testGrande_x.txt\"\n",
    "test_grande_output = \"files/test/\" + problema + \"_testGrande_y.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Elman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 20\n",
    "cpu_size = 10\n",
    "seq_len = 25 # 25\n",
    "\n",
    "num_batches = 10\n",
    "noise_level = 0.4\n",
    "learning_rate = 1e-2\n",
    "l1reg = 1e-4\n",
    "shock = 0.5\n",
    "\n",
    "symbols = ['$', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_many_to_many(num_batches, \n",
    "                                                   seq_len, \n",
    "                                                   input_file=input_file, \n",
    "                                                   output_file=output_file,\n",
    "                                                   chars_x = symbols,\n",
    "                                                   chars_y = ['0', '1'],\n",
    "                                                   longitud=1000000000)\n",
    "\n",
    "dataset_x_train = data_dic['dataset_x'] \n",
    "dataset_y_train = data_dic['dataset_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = rnn_elman.rnn_elman_tf(dim_i, \n",
    "                             hidden_size,\n",
    "                             #cpu_size,\n",
    "                             dim_o,\n",
    "                             learning_rate,\n",
    "                             seq_len=seq_len,\n",
    "                             noise_level=noise_level,\n",
    "                             num_batches=num_batches,\n",
    "                             regularizationL1=l1reg, \n",
    "                             shock=shock,\n",
    "                             clipvalue=5.0,\n",
    "                             #optimizer_name='Adam',\n",
    "                             factor_inicializacion=0.5\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_grafica, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_many_to_many(1, \n",
    "                                                   seq_len, \n",
    "                                                   input_file=input_file, \n",
    "                                                   output_file=output_file,\n",
    "                                                   chars_x = symbols,\n",
    "                                                   chars_y = ['0', '1'],\n",
    "                                                   longitud = 100000000)\n",
    "dataset_x_train, dataset_y_train = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1, \n",
    "                                         seq_len,\n",
    "                                         input_file=test_largas_input, \n",
    "                                         output_file=test_largas_output,\n",
    "                                         chars_x = symbols,\n",
    "                                         chars_y = ['0', '1'],\n",
    "                                         longitud = 100000000)\n",
    "dataset_x_long, dataset_y_long = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "test_largas2_input = \"files/test/\" + problema + \"_cadenasLargas2_x.txt\"\n",
    "test_largas2_output = \"files/test/\" + problema + \"_cadenasLargas2_y.txt\"\n",
    "\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1,\n",
    "                                           seq_len,\n",
    "                                           input_file=test_extremo_muchasA_input, \n",
    "                                           output_file=test_extremo_muchasA_output,\n",
    "                                           chars_x = symbols,\n",
    "                                           chars_y = ['0', '1'],\n",
    "                                           longitud = 100000000)\n",
    "dataset_x_allAs, dataset_y_allAs = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1,\n",
    "                                           seq_len,\n",
    "                                           input_file=test_extremo_muchasB_input, \n",
    "                                           output_file=test_extremo_muchasB_output,\n",
    "                                           chars_x = symbols,\n",
    "                                           chars_y = ['0', '1'],\n",
    "                                           longitud = 100000000)\n",
    "dataset_x_allBs, dataset_y_allBs = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "\n",
    "target, pred, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_train, dataset_y_train)\n",
    "print (\"TEST TRAIN: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_long, dataset_y_long)\n",
    "print (\"TEST LONG: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_allAs, dataset_y_allAs)\n",
    "print (\"TEST EXTREMO A: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_allBs, dataset_y_allBs)\n",
    "print (\"TEST EXTREMO B: \" + str(porcentaje_acierto) + \"% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 20\n",
    "cpu_size = 10\n",
    "seq_len = 25 # 25\n",
    "\n",
    "num_batches = 10\n",
    "noise_level = 0.\n",
    "learning_rate = 1e-2\n",
    "l1reg = 1e-1\n",
    "shock = 0.\n",
    "\n",
    "symbols = ['$', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_many_to_many(num_batches, \n",
    "                                                   seq_len, \n",
    "                                                   input_file=input_file, \n",
    "                                                   output_file=output_file,\n",
    "                                                   chars_x = symbols,\n",
    "                                                   chars_y = ['0', '1'],\n",
    "                                                   longitud=1000000000)\n",
    "\n",
    "dataset_x_train = data_dic['dataset_x'] \n",
    "dataset_y_train = data_dic['dataset_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = rnn_xhcy.rnn_xhcy(dim_i, \n",
    "                        hidden_size,\n",
    "                        cpu_size,\n",
    "                        dim_o,\n",
    "                        learning_rate,\n",
    "                        seq_len=seq_len,\n",
    "                        noise_level=noise_level,\n",
    "                        num_batches=num_batches,\n",
    "                        regularizationL1=l1reg, \n",
    "                        shock=shock,\n",
    "                        clipvalue=5.0,\n",
    "                        #optimizer_name='Adam',\n",
    "                        factor_inicializacion=0.5\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_grafica = rnn_tf.train(rnn, 100, dataset_x_train, dataset_y_train, \n",
    "                            write_tensorboard=False, \n",
    "                            ruido_progresivo=True,\n",
    "                            ruido_min = 1.0,\n",
    "                            ruido_max = 1.0,\n",
    "                            pendiente_ruido = 2.0,\n",
    "                            l1reg_mem_progresivo=True,\n",
    "                            l1reg_mem_min = 0.1,\n",
    "                            l1reg_mem_max = 0.1,\n",
    "                            pendiente_l1reg_mem = 10.0,\n",
    "                            l1reg_cpu_progresivo=True,\n",
    "                            l1reg_cpu_min = 0.0,\n",
    "                            l1reg_cpu_max = 0.0,\n",
    "                            pendiente_l1reg_cpu = 1.0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_grafica, '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_many_to_many(1, \n",
    "                                                   seq_len, \n",
    "                                                   input_file=input_file, \n",
    "                                                   output_file=output_file,\n",
    "                                                   chars_x = symbols,\n",
    "                                                   chars_y = ['0', '1'],\n",
    "                                                   longitud = 100000000)\n",
    "dataset_x_train, dataset_y_train = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1, \n",
    "                                         seq_len,\n",
    "                                         input_file=test_largas_input, \n",
    "                                         output_file=test_largas_output,\n",
    "                                         chars_x = symbols,\n",
    "                                         chars_y = ['0', '1'],\n",
    "                                         longitud = 100000000)\n",
    "dataset_x_long, dataset_y_long = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "test_largas2_input = \"files/test/\" + problema + \"_cadenasLargas2_x.txt\"\n",
    "test_largas2_output = \"files/test/\" + problema + \"_cadenasLargas2_y.txt\"\n",
    "\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1,\n",
    "                                           seq_len,\n",
    "                                           input_file=test_extremo_muchasA_input, \n",
    "                                           output_file=test_extremo_muchasA_output,\n",
    "                                           chars_x = symbols,\n",
    "                                           chars_y = ['0', '1'],\n",
    "                                           longitud = 100000000)\n",
    "dataset_x_allAs, dataset_y_allAs = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "data_dic, _, _, _ = rnn_tf.data_transform_many_to_many(1,\n",
    "                                           seq_len,\n",
    "                                           input_file=test_extremo_muchasB_input, \n",
    "                                           output_file=test_extremo_muchasB_output,\n",
    "                                           chars_x = symbols,\n",
    "                                           chars_y = ['0', '1'],\n",
    "                                           longitud = 100000000)\n",
    "dataset_x_allBs, dataset_y_allBs = data_dic['dataset_x'], data_dic['dataset_y']\n",
    "\n",
    "\n",
    "target, pred, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_train, dataset_y_train)\n",
    "print (\"TEST TRAIN: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_long, dataset_y_long)\n",
    "print (\"TEST LONG: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_allAs, dataset_y_allAs)\n",
    "print (\"TEST EXTREMO A: \" + str(porcentaje_acierto) + \"% accuracy\")\n",
    "prediccion, esperado, porcentaje_acierto = rnn_tf.test(rnn, dataset_x_allBs, dataset_y_allBs)\n",
    "print (\"TEST EXTREMO B: \" + str(porcentaje_acierto) + \"% accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
