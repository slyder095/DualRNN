{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code has been implemented using Tensorflow 1.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import code.rnn_tf as rnn_tf\n",
    "import code.rnn_elman as rnn_elman # Con ruido\n",
    "import code.rnn_xhcy as rnn_xhcy # Dual CPU + Mem (conectada a CPU)\n",
    "\n",
    "import matplotlib.patches as mpatch\n",
    "\n",
    "import time\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posible values: SUMA, SUMA10, SUMA4, SUMA3\n",
    "\n",
    "problema = \"SUMA10\"\n",
    "\n",
    "\n",
    "input_file_s0 = 'files/train/' + problema + '_sumando_0.txt'\n",
    "input_file_s1 = 'files/train/' + problema + '_sumando_1.txt'\n",
    "output_file = 'files/train/' + problema + '_y.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elman RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "cpu_size = 20\n",
    "seq_len = 25\n",
    "\n",
    "num_batches = 10\n",
    "noise_level = 0.4\n",
    "learning_rate = 1e-2\n",
    "l1reg = 1e-4\n",
    "shock = 0.5\n",
    "\n",
    "symbols = ['$', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10\n",
    "\n",
    "ficheros = [input_file_s0, input_file_s1]\n",
    "\n",
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_multiple_inputs_many_to_many(num_batches,\n",
    "                                                                  seq_len,\n",
    "                                                                  input_files=ficheros,\n",
    "                                                                  output_file=output_file,\n",
    "                                                                  chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                                  chars_y = [str(j) for j in range(base)],\n",
    "                                                                  longitud = 1000000)\n",
    "dataset_x_train = data_dic['dataset_x']\n",
    "dataset_y_train = data_dic['dataset_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Optimizador: GradientDescent\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4aad6b440168>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ELMAN + ruido (ICANN'19)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m rnn = rnn_elman.rnn_elman_tf(dim_i, \n\u001b[0m\u001b[1;32m      3\u001b[0m                              \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                              \u001b[0mdim_o\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                              \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Doctorado/GIT/DualRNN/code/rnn_elman.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim_i, dim_h, dim_o, learning_rate, factor_inicializacion, seq_len, num_batches, noise_level, regularizationL1, shock, optimizer_name, clipvalue)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Placeholders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         self.x = tf.placeholder(dtype=tf.float64,\n\u001b[0m\u001b[1;32m     43\u001b[0m                                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdim_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                                 name='input')\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "# ELMAN + ruido (ICANN'19)\n",
    "rnn = rnn_elman.rnn_elman_tf(dim_i, \n",
    "                             hidden_size,\n",
    "                             dim_o,\n",
    "                             learning_rate,\n",
    "                             seq_len=seq_len,\n",
    "                             noise_level=noise_level,\n",
    "                             num_batches=num_batches,\n",
    "                             regularizationL1=l1reg, \n",
    "                             shock=shock,\n",
    "                             clipvalue=5.0,\n",
    "                             #optimizer_name='Adam',\n",
    "                             factor_inicializacion=0.01\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tf.train(rnn, 1000, dataset_x_train, dataset_y_train, \n",
    "             write_tensorboard=False, \n",
    "             ruido_progresivo=True, \n",
    "             ruido_max = 1.0,\n",
    "             pendiente_ruido = 2.0,\n",
    "             l1reg_mem_progresivo=True,\n",
    "             l1reg_mem_max = 1e-1,\n",
    "             pendiente_l1reg_mem = 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficheros = [input_file_s0, input_file_s1]\n",
    "\n",
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_multiple_inputs_many_to_many(1,\n",
    "                                                                  seq_len,\n",
    "                                                                  input_files=ficheros,\n",
    "                                                                  output_file=output_file,\n",
    "                                                                  chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                                  chars_y = [str(j) for j in range(base)],\n",
    "                                                                  longitud = 1000000000)\n",
    "dataset_x_test = data_dic['dataset_x']\n",
    "dataset_y_test = data_dic['dataset_y']\n",
    "\n",
    "target, pred, accuracy = rnn_tf.test(rnn, dataset_x_test, dataset_y_test)\n",
    "print (\"Test:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 10\n",
    "cpu_size = 20\n",
    "seq_len = 25\n",
    "\n",
    "num_batches = 10\n",
    "noise_level = 0.0\n",
    "learning_rate = 1e-2\n",
    "l1reg = 0.0\n",
    "shock = 0.0\n",
    "\n",
    "symbols = ['$', 'a', 'b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 10\n",
    "\n",
    "ficheros = [input_file_s0, input_file_s1]\n",
    "\n",
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_multiple_inputs_many_to_many(num_batches,\n",
    "                                                                  seq_len,\n",
    "                                                                  input_files=ficheros,\n",
    "                                                                  output_file=output_file,\n",
    "                                                                  chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                                  chars_y = [str(j) for j in range(base)],\n",
    "                                                                  longitud = 1000000)\n",
    "dataset_x_train = data_dic['dataset_x']\n",
    "dataset_y_train = data_dic['dataset_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUAL - CPU + Mem (conectada a CPU)\n",
    "rnn = rnn_xhcy.rnn_xhcy(dim_i, \n",
    "                        hidden_size,\n",
    "                        cpu_size,\n",
    "                        dim_o,\n",
    "                        learning_rate,\n",
    "                        seq_len=seq_len,\n",
    "                        noise_level=noise_level,\n",
    "                        num_batches=num_batches,\n",
    "                        regularizationL1=l1reg, \n",
    "                        shock=shock,\n",
    "                        clipvalue=5.0,\n",
    "                        #optimizer_name='Adam',\n",
    "                        factor_inicializacion=0.01\n",
    "                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_tf.train(rnn, 1000, dataset_x_train, dataset_y_train, \n",
    "             write_tensorboard=False, \n",
    "             ruido_progresivo=True, \n",
    "             ruido_max = 1.0,\n",
    "             pendiente_ruido = 2.0,\n",
    "             l1reg_mem_progresivo=True,\n",
    "             l1reg_mem_max = 1e-1,\n",
    "             pendiente_l1reg_mem = 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ficheros = [input_file_s0, input_file_s1]\n",
    "\n",
    "data_dic, dim_i, dim_o, _ = rnn_tf.data_transform_multiple_inputs_many_to_many(1,\n",
    "                                                                  seq_len,\n",
    "                                                                  input_files=ficheros,\n",
    "                                                                  output_file=output_file,\n",
    "                                                                  chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                                  chars_y = [str(j) for j in range(base)],\n",
    "                                                                  longitud = 1000000000)\n",
    "dataset_x_test = data_dic['dataset_x']\n",
    "dataset_y_test = data_dic['dataset_y']\n",
    "\n",
    "target, pred, accuracy = rnn_tf.test(rnn, dataset_x_test, dataset_y_test)\n",
    "print (\"Test:\", accuracy, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = [open(ficheros[i], 'r').read() for i in range(sumandos)]\n",
    "tabla_combinaciones_sin_acarreo = np.ones((base+1, base+1), dtype=int)*(-1)\n",
    "tabla_combinaciones_con_acarreo = np.ones((base+1, base+1), dtype=int)*(-1)\n",
    "\n",
    "acarreo = 0\n",
    "for i, (s1_str, s2_str) in enumerate(zip([s for s in f2[0]], [s for s in f2[1]])):\n",
    "    try:\n",
    "        s1 = int(s1_str)\n",
    "        s2 = int(s2_str)\n",
    "    except:\n",
    "        s1 = -1\n",
    "        s2 = -1\n",
    "    \n",
    "    if acarreo == 0:\n",
    "        if tabla_combinaciones_sin_acarreo[s1][s2] == -1:\n",
    "            tabla_combinaciones_sin_acarreo[s1][s2] = i - 1\n",
    "    elif acarreo == 1:\n",
    "        if tabla_combinaciones_con_acarreo[s1][s2] == -1:\n",
    "            tabla_combinaciones_con_acarreo[s1][s2] = i - 1\n",
    "    \n",
    "    if s1 == -1: acarreo = 0\n",
    "    else: acarreo = (s1+s2+acarreo)/base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn.v_h_prev = np.zeros((hidden_size, 1))\n",
    "\n",
    "hs, ys, inputs, outputs, _, _, hzs, cs = rnn.estados(input_files = ficheros, \n",
    "                                                 output_file = output_file, \n",
    "                                                 longitud=50,\n",
    "                                                 chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                 chars_y = [str(j) for j in range(base)])\n",
    "rnn.v_h_prev = hs[0][:, None]\n",
    "hs, ys, inputs, outputs, _, _, hzs, cs = rnn.estados(input_files = ficheros, \n",
    "                                                 output_file = output_file, \n",
    "                                                 longitud=40000,\n",
    "                                                 chars_x = [str(j) for j in range(base)]+['$'],\n",
    "                                                 chars_y = [str(j) for j in range(base)])\n",
    "\n",
    "hs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wxh = rnn.sess.run(rnn.Wxh)\n",
    "Whh = rnn.sess.run(rnn.Whh)\n",
    "bh = rnn.sess.run(rnn.bh)\n",
    "by = rnn.sess.run(rnn.by)\n",
    "\n",
    "mapa_con_acarreo = []\n",
    "for n in range(hidden_size):\n",
    "    mapa_n = []\n",
    "    \n",
    "    for s1 in range(base):\n",
    "        for s2 in range(base):\n",
    "            vector = np.zeros(base*2+2)[:, None]\n",
    "            vector[s1] = 1\n",
    "            vector[(base+1)+s2] = 1\n",
    "            hprev = hs[tabla_combinaciones_con_acarreo[s1][s2]]\n",
    "            h_z = np.matmul(Wxh, vector) + np.matmul(Whh, hprev[:, None]) + bh\n",
    "            mapa_n.append([s1, s2, np.tanh(h_z[n][0])])\n",
    "\n",
    "    mapa_con_acarreo.append(np.array(mapa_n))\n",
    "    \n",
    "mapa_con_acarreo = np.array(mapa_con_acarreo)\n",
    "\n",
    "mapa_sin_acarreo = []\n",
    "for n in range(hidden_size):\n",
    "    mapa_n = []\n",
    "    \n",
    "    for s1 in range(base):\n",
    "        for s2 in range(base):\n",
    "            vector = np.zeros(base*2+2)[:, None]\n",
    "            vector[s1] = 1\n",
    "            vector[(base+1)+s2] = 1\n",
    "            hprev = hs[tabla_combinaciones_sin_acarreo[s1][s2]]\n",
    "            h_z = np.matmul(Wxh, vector) + np.matmul(Whh, hprev[:, None]) + bh\n",
    "            mapa_n.append([s1, s2, np.tanh(h_z[n][0])])\n",
    "\n",
    "    mapa_sin_acarreo.append(np.array(mapa_n))\n",
    "    \n",
    "mapa_sin_acarreo = np.array(mapa_sin_acarreo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "import IPython.display as display\n",
    "colormap = cm.get_cmap(name='bwr', lut=1000)\n",
    "\n",
    "for neurona in range(hidden_size):\n",
    "    display.display(display.HTML('<h2>Neuron '+str(neurona)+'</h2>'))\n",
    "    colors_con_acarreo = np.zeros((base, base))\n",
    "    for punto in mapa_con_acarreo[neurona]:\n",
    "        colors_con_acarreo[int(punto[0]), int(punto[1])] = punto[2]\n",
    "        \n",
    "    colors_sin_acarreo = np.zeros((base, base))\n",
    "    for punto in mapa_sin_acarreo[neurona]:\n",
    "        colors_sin_acarreo[int(punto[0]), int(punto[1])] = punto[2]\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = fig.gca()\n",
    "    pos = ax.imshow(colors_sin_acarreo, cmap=\"gray\", vmin=-1, vmax=1, origin='lower')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"sum 1\", size=24)\n",
    "    plt.ylabel(\"sum 2\", size=24)\n",
    "    ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = fig.gca()\n",
    "    pos = ax.imshow(colors_con_acarreo, cmap=\"gray\", vmin=-1, vmax=1, origin='lower')\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"sum 1\", size=24)\n",
    "    ax.set_xticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.set_yticks([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "    ax.tick_params(axis='both', labelsize=20)\n",
    "    plt.ylabel(\"\")\n",
    "\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
